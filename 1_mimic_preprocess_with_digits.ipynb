{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we preprocess all the notes in MIMICIII. And do the first step of the preprocessing, including:\n",
    "1. Remove bullet points.\n",
    "2. Fix 'dr.' and 'm.d.' abbreviation.\n",
    "3. Remove '-' and '=='.\n",
    "4. Remove space, keep digits for later preprocessing.\n",
    "\n",
    "Later in the next preprocessing procedure (not included), we will do \n",
    "1. Delete brackets -> Replace all brackets with meaningful tokens - Hausing\n",
    "2. Abbreviation - Hausing\n",
    "3. Replace digit with [num] tokens. - Chutang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gw1107/.conda/envs/NYU_DL/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: load Note datasets\n",
    "# update these constants to run this script\n",
    "preprocessed_data_folder = './Preprocessed_Data/'\n",
    "if not os.path.exists(preprocessed_data_folder):\n",
    "    os.mkdir(preprocessed_data_folder)\n",
    "\n",
    "OUTPUT_DIR =  preprocessed_data_folder#this path will contain tokenized notes. This dir will be the input dir for create_pretrain_data.sh\n",
    "MIMIC_NOTES_FILE = './physionet.org/files/mimiciii/1.4/NOTEEVENTS.csv' #this is the path to mimic data if you're reading from a csv. Else uncomment the code to read from database below\n",
    "\n",
    "df_notes = pd.read_csv(MIMIC_NOTES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # STEP 2: Create the raw file for \n",
    "# number = \"all\"\n",
    "# # numer = 'test'\n",
    "# file=open(OUTPUT_DIR + 'RAW_clinical_sentences_category_{}.txt'.format(number),'w')\n",
    "# all_text_value = df_notes['TEXT'].values\n",
    "# for i in tqdm(range(len(all_text_value))):\n",
    "#     if len(all_text_value[i]) > 0:\n",
    "#         # remove the one token note\n",
    "#         note = all_text_value[i]\n",
    "#         file.write(note+'\\n')\n",
    "#         file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Delete brackets -> Replace all brackets with meaningful tokens - Hausing\n",
    "2. Abbreviation - Hausing \n",
    "3. Replace digit with [num] tokens. - Chutang\n",
    "\n",
    "---- **DONE** ----\n",
    "3. Remove bullet point\n",
    "4. Keep \"date\"\n",
    "5. Keep digit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Preprocessing\n",
    "def preprocess1(x):\n",
    "    '''\n",
    "    This preprocessing does\n",
    "    1. Remove bullet points.\n",
    "    2. Fix 'dr.' and 'm.d.' abbreviation.\n",
    "    3. Remove '-' and '=='.\n",
    "    4. Remove space, keep digits for later preprocessing.\n",
    "    '''\n",
    "    \n",
    "#     y=re.sub('\\\\[(.*?)\\\\]','',x) #remove de-identified brackets\n",
    "    # remove bullepoint like number (what if it's 5.5 mg)\n",
    "    y=re.sub('[0-9]+\\.','',x) #remove 1.2. since the segmenter segments based on this\n",
    "    y=re.sub('dr\\.','doctor',y)\n",
    "    y=re.sub('m\\.d\\.','md',y)\n",
    "    # these two kind of make sense\n",
    "    # y=re.sub('admission date:','',y)\n",
    "    # y=re.sub('discharge date:','',y)\n",
    "    \n",
    "    y=re.sub('--|__|==','',y)\n",
    "    \n",
    "    # remove all digits, spaces\n",
    "    y = y.translate(str.maketrans(\"\", \"\"))\n",
    "    # y = y.translate(str.maketrans(\"\", \"\", string.digits))\n",
    "    y = \" \".join(y.split())\n",
    "    return y\n",
    "\n",
    "\n",
    "def preprocessing(df_notes): \n",
    "    df_notes['TEXT']=df_notes['TEXT'].fillna(' ')\n",
    "    # set to different paragraph\n",
    "    df_notes['TEXT']=df_notes['TEXT'].str.replace('\\n\\n','<paragraph>')\n",
    "    df_notes['TEXT']=df_notes['TEXT'].str.replace('\\n',' ')\n",
    "    df_notes['TEXT']=df_notes['TEXT'].str.replace('\\r',' ')\n",
    "    df_notes['TEXT']=df_notes['TEXT'].apply(str.strip)\n",
    "    df_notes['TEXT']=df_notes['TEXT'].str.lower()\n",
    "\n",
    "    df_notes['TEXT']=df_notes['TEXT'].apply(lambda x: preprocess1(x))\n",
    "    \n",
    "    return df_notes\n",
    "\n",
    "df_notes_fold = preprocessing(df_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083180/2083180 [00:12<00:00, 160330.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Create Pretraining File\n",
    "number = 'with_number'\n",
    "file=open(OUTPUT_DIR + 'Preproc0_clinical_sentences_all_{}.txt'.format(number),'w')\n",
    "pretrain_para_value = df_notes_fold['TEXT'].values\n",
    "for i in tqdm(range(len(df_notes_fold['TEXT']))):\n",
    "    if len(pretrain_para_value[i]) > 0:\n",
    "        # remove the one token note\n",
    "        note = pretrain_para_value[i].replace('<paragraph>','\\n')\n",
    "        file.write(note+'\\n')\n",
    "    file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: Create the preproc0 file for train and val for pretrained longformer \n",
    "\n",
    "ori_fn = OUTPUT_DIR + 'Preproc0_clinical_sentences_all_with_number.txt'\n",
    "train_fn = OUTPUT_DIR + 'Preproc0_clinical_sentences_all_with_number_train.txt'\n",
    "val_fn = OUTPUT_DIR + 'Preproc0_clinical_sentences_all_with_number_val.txt'\n",
    "\n",
    "p = 0.7\n",
    "trainfile = open(train_fn, \"w\")\n",
    "valfile = open(val_fn, \"w\")\n",
    "with open(ori_fn) as bigfile:\n",
    "    for line in bigfile:\n",
    "        writing_file = trainfile\n",
    "        if random.random() > p:\n",
    "            writing_file = valfile  \n",
    "        writing_file.write(line)\n",
    "trainfile.close()\n",
    "valfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
